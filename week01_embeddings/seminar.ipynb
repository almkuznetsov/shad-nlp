{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/almkuznetsov/shad-nlp/blob/main/week01_embeddings/seminar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EcdYm1d0np1"
      },
      "source": [
        "## Practice: Fun with Word Embeddings (4 points total)\n",
        "\n",
        "Today we gonna play with word embeddings: train our own little embeddings, load one from the gensim model zoo and use it to visualize text corpora.\n",
        "\n",
        "This whole thing is gonna happen on top of an embedding dataset.\n",
        "\n",
        "__Requirements:__  `pip install --upgrade nltk gensim bokeh`, but only if you're running locally.\n",
        "\n",
        "**Please submit this notebook as part of your homework!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dGRHAd_F0np3",
        "outputId": "32138028-a0d0-48e5-9120-0f2a04e7bad3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-18 17:23:53--  https://www.dropbox.com/s/obaitrix9jyu84r/quora.txt?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.dropbox.com/scl/fi/p0t2dw6oqs6oxpd6zz534/quora.txt?rlkey=bjupppwua4zmd4elz8octecy9&dl=1 [following]\n",
            "--2025-09-18 17:23:53--  https://www.dropbox.com/scl/fi/p0t2dw6oqs6oxpd6zz534/quora.txt?rlkey=bjupppwua4zmd4elz8octecy9&dl=1\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc1eed4bd6fd385b43a2344d40bd.dl.dropboxusercontent.com/cd/0/inline/CxnqCV86jufjqraAIrdOfFpEp5h3jk0z9hE5C7_VuLLuFWaY1yuDumbfQL2iIjwG8TyALEjSP3i042o-hsLZgBSt_hUpj2GaJbs4TN9voR0vAqKhbthw44-phAnCdbRdurc/file?dl=1# [following]\n",
            "--2025-09-18 17:23:53--  https://uc1eed4bd6fd385b43a2344d40bd.dl.dropboxusercontent.com/cd/0/inline/CxnqCV86jufjqraAIrdOfFpEp5h3jk0z9hE5C7_VuLLuFWaY1yuDumbfQL2iIjwG8TyALEjSP3i042o-hsLZgBSt_hUpj2GaJbs4TN9voR0vAqKhbthw44-phAnCdbRdurc/file?dl=1\n",
            "Resolving uc1eed4bd6fd385b43a2344d40bd.dl.dropboxusercontent.com (uc1eed4bd6fd385b43a2344d40bd.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uc1eed4bd6fd385b43a2344d40bd.dl.dropboxusercontent.com (uc1eed4bd6fd385b43a2344d40bd.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33813903 (32M) [application/binary]\n",
            "Saving to: ‘./quora.txt’\n",
            "\n",
            "./quora.txt         100%[===================>]  32.25M  58.1MB/s    in 0.6s    \n",
            "\n",
            "2025-09-18 17:23:55 (58.1 MB/s) - ‘./quora.txt’ saved [33813903/33813903]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download the data:\n",
        "!wget https://www.dropbox.com/s/obaitrix9jyu84r/quora.txt?dl=1 -O ./quora.txt\n",
        "# alternative download link: https://yadi.sk/i/BPQrUu1NaTduEw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6YYqXYAO0np3",
        "outputId": "813f617a-31a6-49a6-cfef-7f4695de699b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"What TV shows or books help you read people's body language?\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "with open(\"./quora.txt\", encoding=\"utf-8\") as file:\n",
        "    data = list(file)\n",
        "\n",
        "data[50]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNEUPxlE0np3"
      },
      "source": [
        "__Tokenization:__ a typical first step for an NLP task is to split raw data into words.\n",
        "The text we're working with is in raw format: with all the punctuation and emojis attached to some words, so a simple str.split won't do.\n",
        "\n",
        "Let's use __`nltk`__ - a library that handles many NLP tasks like tokenization, stemming, or part-of-speech tagging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sLNA_sgB0np3",
        "outputId": "3f5bc7b9-ad87-4bd0-e945-bddabec4db6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['What', 'TV', 'shows', 'or', 'books', 'help', 'you', 'read', 'people', \"'\", 's', 'body', 'language', '?']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "tokenizer = WordPunctTokenizer()\n",
        "\n",
        "print(tokenizer.tokenize(data[50]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[:3]"
      ],
      "metadata": {
        "id": "k_SR7j1B1ILG",
        "outputId": "daad857d-1dd4-4f8d-ff93-4f09c7206862",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Can I get back with my ex even though she is pregnant with another guy's baby?\\n\",\n",
              " 'What are some ways to overcome a fast food addiction?\\n',\n",
              " 'Who were the great Chinese soldiers and leaders who fought in WW2?\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jrBX0Wkd0np4"
      },
      "outputs": [],
      "source": [
        "# TASK: lowercase everything and extract tokens with tokenizer.\n",
        "# data_tok should be a list of lists of tokens for each line in data.\n",
        "\n",
        "data_tok = [tokenizer.tokenize(elem.lower()) for elem in data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CMpPdJP20np4"
      },
      "outputs": [],
      "source": [
        "assert all(isinstance(row, (list, tuple)) for row in data_tok), \"please convert each line into a list of tokens (strings)\"\n",
        "assert all(all(isinstance(tok, str) for tok in row) for row in data_tok), \"please convert each line into a list of tokens (strings)\"\n",
        "is_latin = lambda tok: all('a' <= x.lower() <= 'z' for x in tok)\n",
        "assert all(map(lambda l: not is_latin(l) or l.islower(), map(' '.join, data_tok))), \"please make sure to lowercase the data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uLO0v1qB0np4",
        "outputId": "e26f505b-db96-4ac8-f5d6-86f681d80dd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"can i get back with my ex even though she is pregnant with another guy ' s baby ?\", 'what are some ways to overcome a fast food addiction ?']\n"
          ]
        }
      ],
      "source": [
        "print([' '.join(row) for row in data_tok[:2]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU42wv6t0np4"
      },
      "source": [
        "__Word vectors:__ as the saying goes, there's more than one way to train word embeddings. There's Word2Vec and GloVe with different objective functions. Then there's fastText that uses character-level models to train word embeddings.\n",
        "\n",
        "The choice is huge, so let's start someplace small: __gensim__ is another NLP library that features many vector-based models including word2vec."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "MKUYvpij2bm9",
        "outputId": "ffa0e5ad-2074-44a8-cafc-05623d713f57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n",
            "Downloading gensim-4.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.1\n",
            "    Uninstalling scipy-1.16.1:\n",
            "      Successfully uninstalled scipy-1.16.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "scipy"
                ]
              },
              "id": "399ac22789bc4a9e9987bade287327cf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "D1xCHuov0np4"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "model = Word2Vec(data_tok,\n",
        "                 vector_size=32,      # embedding vector size\n",
        "                 min_count=5,         # consider words that occurred at least 5 times\n",
        "                 window=5).wv         # define context as a 5-word window around the target word\n",
        "\n",
        "# From gensim docs\n",
        "# wv: This object essentially contains the mapping between words and embeddings.\n",
        "# After training, it can be used directly to query those embeddings in various ways."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UfDMu-sw0np4",
        "outputId": "53076a76-9085-48c6-871e-6392aadf4e55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-3.866831  ,  2.5601013 ,  2.2217479 ,  4.162088  ,  0.82869196,\n",
              "        2.6427882 , -0.9219754 , -3.9565265 ,  1.1939262 ,  2.2731092 ,\n",
              "       -0.9479638 ,  1.9089669 ,  3.041277  ,  1.871703  ,  1.9478456 ,\n",
              "       -1.1388338 , -0.54041195, -0.6175398 ,  0.6114553 , -1.062483  ,\n",
              "       -2.286824  ,  1.2701489 , -0.9546497 , -0.7917746 ,  3.1999147 ,\n",
              "       -3.0546236 , -1.1652448 ,  0.9614959 ,  1.1721421 ,  0.7198902 ,\n",
              "       -0.34250945,  1.1853139 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# now you can get word vectors !\n",
        "model.get_vector('anything')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uVLnWsS30np4",
        "outputId": "a59b1c1d-e877-4dd0-fea8-aba0eecee2f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('dogs', 0.9570890665054321),\n",
              " ('birds', 0.9039656519889832),\n",
              " ('babies', 0.8668861985206604),\n",
              " ('ants', 0.8553656339645386),\n",
              " ('insects', 0.8356104493141174),\n",
              " ('narcissists', 0.8087658882141113),\n",
              " ('pigs', 0.8057934045791626),\n",
              " ('snakes', 0.8040270805358887),\n",
              " ('spiders', 0.7986958026885986),\n",
              " ('animals', 0.7972754836082458)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# or query similar words directly. Go play with it!\n",
        "model.most_similar('cats')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0B5z2cC0np4"
      },
      "source": [
        "### Using pre-trained model\n",
        "\n",
        "Took it a while, huh? Now imagine training life-sized (100~300D) word embeddings on gigabytes of text: Wikipedia articles or Twitter posts.\n",
        "\n",
        "Thankfully, nowadays you can get a pre-trained word embedding model in 2 lines of code (no SMS required, promise).\n",
        "\n",
        "After being downloaded for the first time (or if you manually delete it), the model is saved in the `~/gensim_data` or `%USER_PATH%/gensim_data` directory. This can be checked by setting the return_path parameter to True."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "FgOgFlwQ0np5",
        "outputId": "3c547b41-6633-478e-de69-28714fbc370b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 387.1/387.1MB downloaded\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "model = api.load('glove-twitter-100')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "G7B1IyHf0np5",
        "outputId": "153d7715-2011-4b3e-9ae5-0d8a36374fff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('broker', 0.5820155739784241),\n",
              " ('bonuses', 0.5424473285675049),\n",
              " ('banker', 0.5385112762451172),\n",
              " ('designer', 0.5197198390960693),\n",
              " ('merchandising', 0.4964233338832855),\n",
              " ('treet', 0.4922019839286804),\n",
              " ('shopper', 0.4920562207698822),\n",
              " ('part-time', 0.4912828207015991),\n",
              " ('freelance', 0.4843311905860901),\n",
              " ('aupair', 0.4796452522277832)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "model.most_similar(positive=[\"coder\", \"money\"], negative=[\"brain\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe6lT7rP0np5"
      },
      "source": [
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "# Visualizing data with word embeddings (1 point)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HzM3HBL0np5"
      },
      "source": [
        "One way to see if our vectors are any good is to plot them. Thing is, those vectors are in 30D+ space and we humans are more used to 2-3D.\n",
        "\n",
        "Luckily, we machine learners know about __dimensionality reduction__ methods.\n",
        "\n",
        "Let's use that to plot 1000 most frequent words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QOBMEX-C0np5",
        "outputId": "e9274957-3914-4edd-d971-8c628533cf61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<user>', '_', 'please', 'apa', 'justin', 'text', 'hari', 'playing', 'once', 'sei']\n"
          ]
        }
      ],
      "source": [
        "words = model.index_to_key[:1000]\n",
        "\n",
        "print(words[::100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "X95yhGtm0np5"
      },
      "outputs": [],
      "source": [
        "# for each word, compute its vector with model\n",
        "word_vectors = np.array([model.get_vector(word) for word in words])  # YOUR CODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mLZTiSUA0np5"
      },
      "outputs": [],
      "source": [
        "assert isinstance(word_vectors, np.ndarray)\n",
        "assert word_vectors.shape == (len(words), 100)\n",
        "assert np.isfinite(word_vectors).all()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v7Wo1uM0np5"
      },
      "source": [
        "#### Linear projection: PCA\n",
        "\n",
        "The simplest linear dimensionality reduction method is **P**rincipal **C**omponent **A**nalysis.\n",
        "\n",
        "In geometric terms, PCA tries to find axes along which most of the variance occurs. The \"natural\" axes, if you wish.\n",
        "\n",
        "<img src=\"https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/pca_fish.png\" style=\"width:30%\">\n",
        "\n",
        "\n",
        "Under the hood, it attempts to decompose object-feature matrix $X$ into two smaller matrices: $W$ and $\\hat W$ minimizing _mean squared error_:\n",
        "\n",
        "$$\\|(X W) \\hat{W} - X\\|^2_2 \\to_{W, \\hat{W}} \\min$$\n",
        "- $X \\in \\mathbb{R}^{n \\times m}$ - object matrix (**centered**);\n",
        "- $W \\in \\mathbb{R}^{m \\times d}$ - matrix of direct transformation;\n",
        "- $\\hat{W} \\in \\mathbb{R}^{d \\times m}$ - matrix of reverse transformation;\n",
        "- $n$ samples, $m$ original dimensions and $d$ target dimensions;\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJiJ5bd20np5"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# map word vectors onto 2d plane with PCA. Use good old sklearn API (fit, transform)\n",
        "# after that, normalize vectors to make sure they have zero mean and unit variance\n",
        "word_vectors_pca = []  # YOUR CODE\n",
        "\n",
        "# and maybe MORE OF YOUR CODE here :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erMPFpMg0np5"
      },
      "outputs": [],
      "source": [
        "assert word_vectors_pca.shape == (len(word_vectors), 2), \"there must be a 2d vector for each word\"\n",
        "assert max(abs(word_vectors_pca.mean(0))) < 1e-5, \"points must be zero-centered\"\n",
        "assert max(abs(1.0 - word_vectors_pca.std(0))) < 1e-2, \"points must have unit variance\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WloDqsdL0np5"
      },
      "source": [
        "#### Let's draw it!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bokeh"
      ],
      "metadata": {
        "id": "WXDZJNWA5inN",
        "outputId": "4d2e28e1-f115-4f8c-9995-3ace00bab0c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.12/dist-packages (3.7.3)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.12/dist-packages (from bokeh) (3.1.6)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.12/dist-packages (from bokeh) (1.3.3)\n",
            "Requirement already satisfied: narwhals>=1.13 in /usr/local/lib/python3.12/dist-packages (from bokeh) (2.4.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.12/dist-packages (from bokeh) (1.26.4)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.12/dist-packages (from bokeh) (25.0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from bokeh) (2.2.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from bokeh) (11.3.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.12/dist-packages (from bokeh) (6.0.2)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.12/dist-packages (from bokeh) (6.4.2)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.12/dist-packages (from bokeh) (2025.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from Jinja2>=2.9->bokeh) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->bokeh) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->bokeh) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->bokeh) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2->bokeh) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "fcax2VWk0np5"
      },
      "outputs": [],
      "source": [
        "import bokeh.models as bm, bokeh.plotting as pl\n",
        "from bokeh.io import output_notebook\n",
        "output_notebook()\n",
        "\n",
        "def draw_vectors(x, y, radius=10, alpha=0.25, color='blue',\n",
        "                 width=600, height=400, show=True, **kwargs):\n",
        "    \"\"\" draws an interactive plot for data points with auxilirary info on hover \"\"\"\n",
        "    if isinstance(color, str): color = [color] * len(x)\n",
        "    data_source = bm.ColumnDataSource({ 'x' : x, 'y' : y, 'color': color, **kwargs })\n",
        "\n",
        "    fig = pl.figure(active_scroll='wheel_zoom', width=width, height=height)\n",
        "    fig.scatter('x', 'y', size=radius, color='color', alpha=alpha, source=data_source)\n",
        "\n",
        "    fig.add_tools(bm.HoverTool(tooltips=[(key, \"@\" + key) for key in kwargs.keys()]))\n",
        "    if show: pl.show(fig)\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7m-6HJs50np5"
      },
      "outputs": [],
      "source": [
        "draw_vectors(word_vectors_pca[:, 0], word_vectors_pca[:, 1], token=words)\n",
        "\n",
        "# hover a mouse over there and see if you can identify the clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBl7oPhO0np5"
      },
      "source": [
        "#### Visualizing neighbors with t-SNE\n",
        "PCA is nice but it's strictly linear and thus only able to capture coarse high-level structure of the data.\n",
        "\n",
        "If we instead want to focus on keeping neighboring points near, we could use TSNE, which is itself an embedding method. Here you can read __[more on TSNE](https://distill.pub/2016/misread-tsne/)__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nL18rOFq0np5"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# map word vectors onto 2d plane with TSNE. hint: don't panic, it may take a minute or two to fit.\n",
        "# normalize them as just like with PCA\n",
        "\n",
        "\n",
        "word_tsne = TSNE().fit_transform(word_vectors)  # YOUR CODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "vckV1UCW0np5",
        "outputId": "e2bcb8ce-34c5-4e2a-faf9-739e307dae6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "'use strict';\n",
              "(function(root) {\n",
              "  function now() {\n",
              "    return new Date();\n",
              "  }\n",
              "\n",
              "  const force = true;\n",
              "\n",
              "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
              "    root._bokeh_onload_callbacks = [];\n",
              "    root._bokeh_is_loading = undefined;\n",
              "  }\n",
              "\n",
              "const JS_MIME_TYPE = 'application/javascript';\n",
              "  const HTML_MIME_TYPE = 'text/html';\n",
              "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
              "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
              "\n",
              "  /**\n",
              "   * Render data to the DOM node\n",
              "   */\n",
              "  function render(props, node) {\n",
              "    const script = document.createElement(\"script\");\n",
              "    node.appendChild(script);\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when an output is cleared or removed\n",
              "   */\n",
              "  function handleClearOutput(event, handle) {\n",
              "    function drop(id) {\n",
              "      const view = Bokeh.index.get_by_id(id)\n",
              "      if (view != null) {\n",
              "        view.model.document.clear()\n",
              "        Bokeh.index.delete(view)\n",
              "      }\n",
              "    }\n",
              "\n",
              "    const cell = handle.cell;\n",
              "\n",
              "    const id = cell.output_area._bokeh_element_id;\n",
              "    const server_id = cell.output_area._bokeh_server_id;\n",
              "\n",
              "    // Clean up Bokeh references\n",
              "    if (id != null) {\n",
              "      drop(id)\n",
              "    }\n",
              "\n",
              "    if (server_id !== undefined) {\n",
              "      // Clean up Bokeh references\n",
              "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
              "      cell.notebook.kernel.execute(cmd_clean, {\n",
              "        iopub: {\n",
              "          output: function(msg) {\n",
              "            const id = msg.content.text.trim()\n",
              "            drop(id)\n",
              "          }\n",
              "        }\n",
              "      });\n",
              "      // Destroy server and session\n",
              "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
              "      cell.notebook.kernel.execute(cmd_destroy);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when a new output is added\n",
              "   */\n",
              "  function handleAddOutput(event, handle) {\n",
              "    const output_area = handle.output_area;\n",
              "    const output = handle.output;\n",
              "\n",
              "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
              "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
              "      return\n",
              "    }\n",
              "\n",
              "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
              "\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
              "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
              "      // store reference to embed id on output_area\n",
              "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
              "    }\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
              "      const bk_div = document.createElement(\"div\");\n",
              "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "      const script_attrs = bk_div.children[0].attributes;\n",
              "      for (let i = 0; i < script_attrs.length; i++) {\n",
              "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
              "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
              "      }\n",
              "      // store reference to server id on output_area\n",
              "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
              "    }\n",
              "  }\n",
              "\n",
              "  function register_renderer(events, OutputArea) {\n",
              "\n",
              "    function append_mime(data, metadata, element) {\n",
              "      // create a DOM node to render to\n",
              "      const toinsert = this.create_output_subarea(\n",
              "        metadata,\n",
              "        CLASS_NAME,\n",
              "        EXEC_MIME_TYPE\n",
              "      );\n",
              "      this.keyboard_manager.register_events(toinsert);\n",
              "      // Render to node\n",
              "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
              "      render(props, toinsert[toinsert.length - 1]);\n",
              "      element.append(toinsert);\n",
              "      return toinsert\n",
              "    }\n",
              "\n",
              "    /* Handle when an output is cleared or removed */\n",
              "    events.on('clear_output.CodeCell', handleClearOutput);\n",
              "    events.on('delete.Cell', handleClearOutput);\n",
              "\n",
              "    /* Handle when a new output is added */\n",
              "    events.on('output_added.OutputArea', handleAddOutput);\n",
              "\n",
              "    /**\n",
              "     * Register the mime type and append_mime function with output_area\n",
              "     */\n",
              "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
              "      /* Is output safe? */\n",
              "      safe: true,\n",
              "      /* Index of renderer in `output_area.display_order` */\n",
              "      index: 0\n",
              "    });\n",
              "  }\n",
              "\n",
              "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
              "  if (root.Jupyter !== undefined) {\n",
              "    const events = require('base/js/events');\n",
              "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
              "\n",
              "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
              "      register_renderer(events, OutputArea);\n",
              "    }\n",
              "  }\n",
              "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
              "    root._bokeh_timeout = Date.now() + 5000;\n",
              "    root._bokeh_failed_load = false;\n",
              "  }\n",
              "\n",
              "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
              "     \"<div style='background-color: #fdd'>\\n\"+\n",
              "     \"<p>\\n\"+\n",
              "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
              "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
              "     \"</p>\\n\"+\n",
              "     \"<ul>\\n\"+\n",
              "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
              "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
              "     \"</ul>\\n\"+\n",
              "     \"<code>\\n\"+\n",
              "     \"from bokeh.resources import INLINE\\n\"+\n",
              "     \"output_notebook(resources=INLINE)\\n\"+\n",
              "     \"</code>\\n\"+\n",
              "     \"</div>\"}};\n",
              "\n",
              "  function display_loaded(error = null) {\n",
              "    const el = document.getElementById(null);\n",
              "    if (el != null) {\n",
              "      const html = (() => {\n",
              "        if (typeof root.Bokeh === \"undefined\") {\n",
              "          if (error == null) {\n",
              "            return \"BokehJS is loading ...\";\n",
              "          } else {\n",
              "            return \"BokehJS failed to load.\";\n",
              "          }\n",
              "        } else {\n",
              "          const prefix = `BokehJS ${root.Bokeh.version}`;\n",
              "          if (error == null) {\n",
              "            return `${prefix} successfully loaded.`;\n",
              "          } else {\n",
              "            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n",
              "          }\n",
              "        }\n",
              "      })();\n",
              "      el.innerHTML = html;\n",
              "\n",
              "      if (error != null) {\n",
              "        const wrapper = document.createElement(\"div\");\n",
              "        wrapper.style.overflow = \"auto\";\n",
              "        wrapper.style.height = \"5em\";\n",
              "        wrapper.style.resize = \"vertical\";\n",
              "        const content = document.createElement(\"div\");\n",
              "        content.style.fontFamily = \"monospace\";\n",
              "        content.style.whiteSpace = \"pre-wrap\";\n",
              "        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n",
              "        content.textContent = error.stack ?? error.toString();\n",
              "        wrapper.append(content);\n",
              "        el.append(wrapper);\n",
              "      }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(() => display_loaded(error), 100);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  function run_callbacks() {\n",
              "    try {\n",
              "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
              "        if (callback != null)\n",
              "          callback();\n",
              "      });\n",
              "    } finally {\n",
              "      delete root._bokeh_onload_callbacks\n",
              "    }\n",
              "    console.debug(\"Bokeh: all callbacks have finished\");\n",
              "  }\n",
              "\n",
              "  function load_libs(css_urls, js_urls, callback) {\n",
              "    if (css_urls == null) css_urls = [];\n",
              "    if (js_urls == null) js_urls = [];\n",
              "\n",
              "    root._bokeh_onload_callbacks.push(callback);\n",
              "    if (root._bokeh_is_loading > 0) {\n",
              "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
              "      return null;\n",
              "    }\n",
              "    if (js_urls == null || js_urls.length === 0) {\n",
              "      run_callbacks();\n",
              "      return null;\n",
              "    }\n",
              "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
              "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
              "\n",
              "    function on_load() {\n",
              "      root._bokeh_is_loading--;\n",
              "      if (root._bokeh_is_loading === 0) {\n",
              "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
              "        run_callbacks()\n",
              "      }\n",
              "    }\n",
              "\n",
              "    function on_error(url) {\n",
              "      console.error(\"failed to load \" + url);\n",
              "    }\n",
              "\n",
              "    for (let i = 0; i < css_urls.length; i++) {\n",
              "      const url = css_urls[i];\n",
              "      const element = document.createElement(\"link\");\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error.bind(null, url);\n",
              "      element.rel = \"stylesheet\";\n",
              "      element.type = \"text/css\";\n",
              "      element.href = url;\n",
              "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
              "      document.body.appendChild(element);\n",
              "    }\n",
              "\n",
              "    for (let i = 0; i < js_urls.length; i++) {\n",
              "      const url = js_urls[i];\n",
              "      const element = document.createElement('script');\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error.bind(null, url);\n",
              "      element.async = false;\n",
              "      element.src = url;\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "  };\n",
              "\n",
              "  function inject_raw_css(css) {\n",
              "    const element = document.createElement(\"style\");\n",
              "    element.appendChild(document.createTextNode(css));\n",
              "    document.body.appendChild(element);\n",
              "  }\n",
              "\n",
              "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.7.3.min.js\"];\n",
              "  const css_urls = [];\n",
              "\n",
              "  const inline_js = [    function(Bokeh) {\n",
              "      Bokeh.set_log_level(\"info\");\n",
              "    },\n",
              "function(Bokeh) {\n",
              "    }\n",
              "  ];\n",
              "\n",
              "  function run_inline_js() {\n",
              "    if (root.Bokeh !== undefined || force === true) {\n",
              "      try {\n",
              "            for (let i = 0; i < inline_js.length; i++) {\n",
              "      inline_js[i].call(root, root.Bokeh);\n",
              "    }\n",
              "\n",
              "      } catch (error) {throw error;\n",
              "      }} else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(run_inline_js, 100);\n",
              "    } else if (!root._bokeh_failed_load) {\n",
              "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
              "      root._bokeh_failed_load = true;\n",
              "    } else if (force !== true) {\n",
              "      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
              "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
              "    }\n",
              "  }\n",
              "\n",
              "  if (root._bokeh_is_loading === 0) {\n",
              "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
              "    run_inline_js();\n",
              "  } else {\n",
              "    load_libs(css_urls, js_urls, function() {\n",
              "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
              "      run_inline_js();\n",
              "    });\n",
              "  }\n",
              "}(window));"
            ],
            "application/vnd.bokehjs_load.v0+json": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(null);\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.7.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {throw error;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"aabf325d-0269-44d2-aeb3-cd7294c6995e\" data-root-id=\"p1006\" style=\"display: contents;\"></div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "(function(root) {\n",
              "  function embed_document(root) {\n",
              "  const docs_json = {\"62fe4401-44d6-4f59-8d9e-103fec13f267\":{\"version\":\"3.7.3\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1006\",\"attributes\":{\"height\":400,\"x_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1007\"},\"y_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1008\"},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1015\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1016\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1013\"},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1046\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1003\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1004\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1005\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[1000],\"dtype\":\"float32\",\"order\":\"little\"}],[\"y\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[1000],\"dtype\":\"float32\",\"order\":\"little\"}],[\"color\",[\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\"]],[\"token\",[\"<user>\",\".\",\":\",\"rt\",\",\",\"<repeat>\",\"<hashtag>\",\"<number>\",\"<url>\",\"!\",\"i\",\"a\",\"\\\"\",\"the\",\"?\",\"you\",\"to\",\"(\",\"<allcaps>\",\"<elong>\",\")\",\"me\",\"de\",\"<smile>\",\"\\uff01\",\"que\",\"and\",\"\\u3002\",\"-\",\"my\",\"no\",\"\\u3001\",\"is\",\"it\",\"\\u2026\",\"in\",\"n\",\"for\",\"/\",\"of\",\"la\",\"'s\",\"*\",\"do\",\"n't\",\"that\",\"on\",\"y\",\"'\",\"e\",\"o\",\"u\",\"en\",\"this\",\"el\",\"so\",\"be\",\"'m\",\"with\",\"just\",\">\",\"your\",\"^\",\"like\",\"have\",\"te\",\"at\",\"\\uff1f\",\"love\",\"se\",\"are\",\"<\",\"m\",\"r\",\"if\",\"all\",\"b\",\"\\u30fb\",\"not\",\"but\",\"we\",\"es\",\"ya\",\"&\",\"follow\",\"up\",\"what\",\"get\",\"lol\",\"un\",\"\\u2665\",\"lo\",\"when\",\"was\",\"\\u201c\",\"\\u201d\",\"one\",\"por\",\"si\",\"out\",\"_\",\"mi\",\"can\",\"<sadface>\",\"\\u0645\\u0646\",\"\\u2661\",\"\\u00b4\",\"he\",\"con\",\"they\",\"now\",\"go\",\"\\u060c\",\"para\",\"los\",\"know\",\"haha\",\"good\",\"tu\",\"back\",\"~\",\"about\",\"new\",\";\",\"as\",\"day\",\"how\",\"who\",\"will\",\"want\",\"people\",\"yo\",\"eu\",\"from\",\"di\",\"time\",\"<heart>\",\"s\",\"aku\",\"da\",\"'re\",\"<lolface>\",\"una\",\"got\",\"las\",\"more\",\"x\",\"she\",\"today\",\"\\uff08\",\">>\",\"k\",\"by\",\"or\",\"\\u0641\\u064a\",\"\\uff65\",\"too\",\"le\",\"\\u00e9\",\"|\",\"[\",\"\\uff09\",\"]\",\"see\",\"why\",\"yg\",\"ca\",\"como\",\"her\",\"\\u2014\",\"q\",\"need\",\"an\",\"na\",\"\\u7b11\",\"there\",\"\\u03c9\",\"happy\",\"im\",\"mas\",\"je\",\"life\",\"really\",\"make\",\"yang\",\"shit\",\"think\",\"t\",\"\\u2764\",\"n\\u00e3o\",\"never\",\"some\",\"\\uff5e\",\"oh\",\"\\u2605\",\"did\",\"would\",\"del\",\"`\",\"d\",\"please\",\"via\",\"much\",\"fuck\",\"al\",\"dia\",\"$\",\"\\u0648\",\"right\",\"best\",\"c\",\"going\",\"\\u0627\\u0644\\u0644\\u0647\",\"pero\",\"only\",\"has\",\"\\u266a\",\"'ll\",\"twitter\",\"=\",\"hahaha\",\"its\",\"nn\",\"\\uff40\",\"\\u00bf\",\"am\",\"say\",\"<neutralface>\",\"them\",\"here\",\"\\u0644\\u0627\",\"off\",\"still\",\"dan\",\"+\",\"night\",\"w\",\"ada\",\"someone\",\"even\",\"then\",\"\\u2606\",\"ni\",\"come\",\"com\",\"always\",\"man\",\"'ve\",\"been\",\"his\",\"itu\",\"\\u0639\\u0644\\u0649\",\"-_-\",\"\\u263a\",\"over\",\"um\",\"\\u0645\\u0627\",\"hate\",\"girl\",\"ai\",\"had\",\"pra\",\"todo\",\"mais\",\"feel\",\"let\",\"ini\",\"because\",\"\\uff9f\",\"thanks\",\"ah\",\"way\",\"ever\",\"look\",\"tweet\",\"followers\",\"should\",\"our\",\"xd\",\"aja\",\"esta\",\"school\",\"him\",\"ser\",\"take\",\"than\",\"video\",\"em\",\"last\",\"wanna\",\"does\",\"us\",\"miss\",\"l\",\"ga\",\"better\",\"well\",\"could\",\"\\u25bd\",\"%\",\"apa\",\"cuando\",\"team\",\"\\u2714\",\"@\",\"ok\",\"\\u061f\",\"\\u2022\",\"vida\",\"quiero\",\"les\",\"being\",\"real\",\"down\",\"kamu\",\"everyone\",\"gonna\",\"live\",\"tonight\",\"yes\",\"work\",\"ass\",\"retweet\",\"nada\",\"sama\",\"first\",\"<<\",\"photo\",\"tomorrow\",\"where\",\"god\",\"son\",\"ke\",\"ta\",\"f\",\"home\",\"lagi\",\"thank\",\"birthday\",\"\\u2588\",\"ha\",\"great\",\"lmao\",\"omg\",\"morning\",\"m\\u00e1s\",\"mau\",\"baby\",\"dont\",\"\\uff61\",\"their\",\"p\",\"things\",\"game\",\"pas\",\"bad\",\"year\",\"yeah\",\"su\",\"bitch\",\"\\u0432\",\"stop\",\"hoy\",\"something\",\"meu\",\"tak\",\"gak\",\"world\",\"amor\",\"h\",\"\\\\\",\"ver\",\"\\uff1b\",\"porque\",\"give\",\"these\",\"\\u0627\\u0644\\u0644\\u0647\\u0645\",\"were\",\"hay\",\"sleep\",\"gue\",\"every\",\"friends\",\"uma\",\"tell\",\"amo\",\"vou\",\"bien\",\"\\u00a1\",\"again\",\"\\uff3e\",\"\\uff0f\",\"done\",\"after\",\"todos\",\"girls\",\"guys\",\"getting\",\"big\",\"wait\",\"justin\",\"eh\",\"\\u2192\",\"kan\",\"kita\",\"jajaja\",\"wish\",\"said\",\"fucking\",\"show\",\"thing\",\"next\",\"voc\\u00ea\",\"nos\",\"little\",\"tengo\",\"keep\",\"person\",\"''\",\"\\u2200\",\"hope\",\"\\u0643\\u0644\",\"hey\",\"bisa\",\"free\",\"made\",\"foto\",\"va\",\"everything\",\"iya\",\"nigga\",\"eso\",\"et\",\"watch\",\"music\",\"week\",\"talk\",\"ne\",\"solo\",\"gente\",\"udah\",\"\\uff1a\",\"--\",\"\\uff3c\",\"mejor\",\"facebook\",\"ma\",\"v\",\"phone\",\"most\",\"same\",\"okay\",\"ik\",\"before\",\"minha\",\"days\",\"g\",\"ti\",\"damn\",\"nice\",\"voy\",\"vai\",\"call\",\"long\",\"tapi\",\"http\",\"sin\",\"nunca\",\"doing\",\"other\",\"find\",\"il\",\"sa\",\"sorry\",\"nya\",\"orang\",\"\\u00b0\",\"hard\",\"mean\",\"die\",\"\\u0627\\u0644\\u0644\\u064a\",\"tem\",\"soy\",\"este\",\"kalo\",\"s\\u00f3\",\"th\",\"win\",\"nothing\",\"into\",\"face\",\"cute\",\"'d\",\"gracias\",\"lah\",\"\\u0438\",\"any\",\"play\",\"\\u2190\",\"ko\",\"text\",\"\\u2323\",\"estoy\",\"tau\",\"ur\",\"buat\",\"#\",\"cause\",\"\\u044f\",\"put\",\"kau\",\"siempre\",\"juga\",\"casa\",\"\\u0623\\u0646\",\"help\",\"start\",\"feliz\",\"old\",\"ir\",\"very\",\"care\",\"bir\",\"makes\",\"song\",\"check\",\"watching\",\"ahora\",\"jadi\",\"os\",\"may\",\"friend\",\"beautiful\",\"heart\",\"ka\",\"vc\",\"mundo\",\"\\u043d\\u0430\",\"sure\",\"tan\",\"pretty\",\"aqui\",\"\\u043d\\u0435\",\"house\",\"\\u0631\\u062a\\u0648\\u064a\\u062a\",\"\\u064a\\u0627\",\"ja\",\"true\",\"muy\",\"away\",\"already\",\"actually\",\"believe\",\"try\",\"many\",\"ma\\u00f1ana\",\"mis\",\"lu\",\"those\",\"hot\",\"qu\\u00e9\",\"mal\",\"\\u0639\\u0646\",\"though\",\"ask\",\"amazing\",\"bed\",\"}\",\"two\",\"mom\",\"d\\u00eda\",\"ve\",\"dari\",\"gameinsight\",\"stay\",\"fun\",\"around\",\"van\",\"cont\",\"ready\",\"money\",\"bu\",\"funny\",\"cool\",\"hair\",\"\\u00e0\",\"tho\",\"{\",\"wo\",\"hi\",\"name\",\"tiene\",\"hahahaha\",\"pa\",\"algo\",\"gotta\",\"\\u0648\\u0644\\u0627\",\"boy\",\"another\",\"c'est\",\"hari\",\"jajajaja\",\"having\",\"cara\",\"jaja\",\"dm\",\"looking\",\"top\",\"android\",\"dah\",\"wow\",\"\\u2591\",\"eres\",\"ben\",\"must\",\"news\",\"met\",\"est\\u00e1\",\"nih\",\"family\",\"black\",\"thought\",\"nak\",\"super\",\"end\",\"hace\",\"remember\",\"ama\",\"party\",\"cant\",\"vamos\",\"anything\",\"anyone\",\"\\u0641\\u0648\\u0644\\u0648\",\"perfect\",\"guy\",\"vez\",\"christmas\",\"dos\",\"bueno\",\"nao\",\"years\",\"vote\",\"dormir\",\"bro\",\"else\",\"quien\",\"untuk\",\"jangan\",\"myself\",\"head\",\"mind\",\"gua\",\"talking\",\"while\",\"dat\",\"food\",\"\\u0434\",\"coming\",\"wkwk\",\"trying\",\"saya\",\"mucho\",\"without\",\"wrong\",\"\\u2019s\",\"baru\",\"__\",\"hehe\",\"hacer\",\"lot\",\"followed\",\"crazy\",\"hell\",\"feeling\",\"des\",\"kok\",\"j\",\"stats\",\"j'\",\"\\u0627\\u0646\",\"tweets\",\"non\",\"cosas\",\"era\",\"high\",\"niggas\",\"change\",\"movie\",\"xx\",\"mad\",\"sih\",\"sometimes\",\"deh\",\"allah\",\"through\",\"pour\",\"ela\",\"soon\",\"gone\",\"playing\",\"smile\",\"bukan\",\"tv\",\"fans\",\"hasta\",\"akan\",\"y'\",\"looks\",\"isso\",\"\\u270c\",\"tired\",\"boys\",\"might\",\"dong\",\"lg\",\"use\",\"maybe\",\"until\",\"menos\",\"own\",\"dengan\",\"eat\",\"ou\",\"weekend\",\"\\u02d8\",\"class\",\"ele\",\"harry\",\"iphone\",\"friday\",\"single\",\"ff\",\"awesome\",\"bout\",\"muito\",\"hoje\",\"\\u00ac\",\"dios\",\"such\",\"estar\",\"j\\u00e1\",\"quando\",\"esa\",\"making\",\"\\u2501\",\"times\",\"lmfao\",\"gw\",\"moment\",\"yet\",\"aw\",\"smh\",\"banget\",\"masih\",\"qui\",\"quem\",\"\\u2013\",\"leave\",\"du\",\"une\",\"guess\",\"hit\",\"\\u0441\",\"pm\",\"since\",\"pues\",\"est\",\"job\",\"\\uff89\",\"mana\",\"bom\",\"siapa\",\"suka\",\"bieber\",\"mention\",\"lebih\",\"favorite\",\"bitches\",\"forever\",\"\\u0644\\u064a\",\"final\",\"read\",\"alguien\",\"open\",\"yourself\",\"ese\",\"che\",\"sex\",\"yaa\",\"car\",\"direction\",\"tidak\",\"seu\",\"gets\",\"left\",\"re\",\"jam\",\"enough\",\"\\u0625\\u0644\\u0627\",\"once\",\"\\u2019\",\"part\",\"cada\",\"\\u5b9a\\u671f\",\"\\u0644\\u0643\",\"een\",\"seen\",\"kak\",\"as\\u00ed\",\"nem\",\"\\u0639\\u0645\\u0644\",\"white\",\"told\",\"says\",\"esto\",\"sad\",\"mo\",\"fue\",\"yah\",\"summer\",\"\\u0647\",\"\\u2b55\",\"\\u00bb\",\"thats\",\"\\u0645\\u0639\",\"posted\",\"wants\",\"agora\",\"together\",\"fan\",\"men\",\"hear\",\"full\",\"\\u2600\",\"sigo\",\"pq\",\"dulu\",\"plus\",\"foi\",\"tudo\",\"\\u0647\\u0648\",\"ill\",\"\\u3042\",\"thinking\",\"wtf\",\"pagi\",\"mama\",\"kalau\",\"hati\",\"sexy\",\"sayang\",\"baik\",\"semua\",\"hola\",\"went\",\"vos\",\"tanto\",\"finally\",\"fb\",\"sea\",\"stupid\",\"tus\",\"seriously\",\"hora\",\"min\",\"pic\",\"estas\",\"turn\",\"hours\",\"excited\",\"nah\",\"buy\",\"saying\",\"mah\",\"break\",\"needs\",\"ce\",\"room\",\"choice\",\"far\",\"dead\",\"quero\",\"saw\",\"kids\",\"lil\",\"whole\",\"puede\",\"fall\",\"sus\",\"lost\",\"asi\",\"word\",\"\\u2639\",\"also\",\"\\u0631\\u064a\\u062a\\u0648\\u064a\\u062a\",\"probably\",\"everybody\",\"tarde\",\"run\",\"sei\",\"follback\",\"forget\",\"sweet\",\"welcome\",\"selamat\",\"\\uff3f\",\"sur\",\"place\",\"gusta\",\"sabe\",\"androidgames\",\"tp\",\"tiempo\",\"\\u0628\\u0633\",\"sou\",\"tuh\",\"vs\",\"eyes\",\"\\u0627\\u0646\\u0627\",\"picture\",\"das\",\"meet\",\"anak\",\"persona\",\"essa\",\"bored\",\"following\",\"nadie\",\"nobody\",\"dice\",\"alone\",\"sick\",\"red\",\"city\",\"cinta\",\"\\u6708\",\"linda\",\"dream\",\"story\",\"km\",\"het\",\"waiting\",\"^_^\",\"mine\",\"\\u0447\\u0442\\u043e\",\"reason\",\"kk\",\"\\u0644\\u0648\",\"online\",\"fast\",\"udh\",\"wanted\",\"op\",\"others\",\"gay\",\"n\\u2019t\",\"used\",\"sem\",\"understand\",\"moi\",\"sm\",\"aint\",\"donde\",\"bem\",\"which\",\"ng\",\"followback\",\"punya\",\"late\",\"anda\",\"tidur\",\"puedo\",\"early\",\"nd\",\"personas\",\"banyak\",\"\\u2705\",\"\\u278a\",\"trust\",\"noche\",\"tl\",\"\\uff1e\",\"\\u00ab\",\"af\",\"move\",\"pro\",\"bring\",\"ku\",\"called\",\"relationship\",\"idk\",\"hurt\",\"st\",\"pernah\",\"pessoas\",\"hello\",\"uno\",\"unfollowers\",\"cry\"]]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1047\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1048\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1043\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":10},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.25},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.25},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.25}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1044\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":10},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1045\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":10},\"line_color\":{\"type\":\"field\",\"field\":\"color\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"field\",\"field\":\"color\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1014\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p1027\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p1028\",\"attributes\":{\"renderers\":\"auto\"}},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p1029\",\"attributes\":{\"dimensions\":\"both\",\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p1030\",\"attributes\":{\"syncable\":false,\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5,\"level\":\"overlay\",\"visible\":false,\"left\":{\"type\":\"number\",\"value\":\"nan\"},\"right\":{\"type\":\"number\",\"value\":\"nan\"},\"top\":{\"type\":\"number\",\"value\":\"nan\"},\"bottom\":{\"type\":\"number\",\"value\":\"nan\"},\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"top_units\":\"canvas\",\"bottom_units\":\"canvas\",\"handles\":{\"type\":\"object\",\"name\":\"BoxInteractionHandles\",\"id\":\"p1036\",\"attributes\":{\"all\":{\"type\":\"object\",\"name\":\"AreaVisuals\",\"id\":\"p1035\",\"attributes\":{\"fill_color\":\"white\",\"hover_fill_color\":\"lightgray\"}}}}}}}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p1037\"},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p1038\"},{\"type\":\"object\",\"name\":\"HelpTool\",\"id\":\"p1039\"},{\"type\":\"object\",\"name\":\"HoverTool\",\"id\":\"p1049\",\"attributes\":{\"renderers\":\"auto\",\"tooltips\":[[\"token\",\"@token\"]]}}],\"active_scroll\":{\"id\":\"p1028\"}}},\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1022\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1023\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1024\"},\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1025\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1017\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1018\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1019\"},\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1020\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1021\",\"attributes\":{\"axis\":{\"id\":\"p1017\"}}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1026\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1022\"}}}]}}]}};\n",
              "  const render_items = [{\"docid\":\"62fe4401-44d6-4f59-8d9e-103fec13f267\",\"roots\":{\"p1006\":\"aabf325d-0269-44d2-aeb3-cd7294c6995e\"},\"root_ids\":[\"p1006\"]}];\n",
              "  void root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "  }\n",
              "  if (root.Bokeh !== undefined) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    let attempts = 0;\n",
              "    const timer = setInterval(function(root) {\n",
              "      if (root.Bokeh !== undefined) {\n",
              "        clearInterval(timer);\n",
              "        embed_document(root);\n",
              "      } else {\n",
              "        attempts++;\n",
              "        if (attempts > 100) {\n",
              "          clearInterval(timer);\n",
              "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
              "        }\n",
              "      }\n",
              "    }, 10, root)\n",
              "  }\n",
              "})(window);"
            ],
            "application/vnd.bokehjs_exec.v0+json": ""
          },
          "metadata": {
            "application/vnd.bokehjs_exec.v0+json": {
              "id": "p1006"
            }
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "figure(id='p1006', ...)"
            ],
            "text/html": [
              "<div style=\"display: table;\"><div style=\"display: table-row;\"><div style=\"display: table-cell;\"><b title=\"bokeh.plotting._figure.figure\">figure</b>(</div><div style=\"display: table-cell;\">id&nbsp;=&nbsp;'p1006', <span id=\"p1053\" style=\"cursor: pointer;\">&hellip;)</span></div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">above&nbsp;=&nbsp;[],</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">align&nbsp;=&nbsp;'auto',</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">aspect_ratio&nbsp;=&nbsp;None,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">aspect_scale&nbsp;=&nbsp;1,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">attribution&nbsp;=&nbsp;[],</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">background_fill_alpha&nbsp;=&nbsp;1.0,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">background_fill_color&nbsp;=&nbsp;'#ffffff',</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">background_hatch_alpha&nbsp;=&nbsp;1.0,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">background_hatch_color&nbsp;=&nbsp;'black',</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">background_hatch_extra&nbsp;=&nbsp;{},</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">background_hatch_pattern&nbsp;=&nbsp;None,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">background_hatch_scale&nbsp;=&nbsp;12.0,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">background_hatch_weight&nbsp;=&nbsp;1.0,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">below&nbsp;=&nbsp;[LinearAxis(id='p1017', ...)],</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">border_fill_alpha&nbsp;=&nbsp;1.0,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">border_fill_color&nbsp;=&nbsp;'#ffffff',</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">border_hatch_alpha&nbsp;=&nbsp;1.0,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">border_hatch_color&nbsp;=&nbsp;'black',</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">border_hatch_extra&nbsp;=&nbsp;{},</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">border_hatch_pattern&nbsp;=&nbsp;None,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">border_hatch_scale&nbsp;=&nbsp;12.0,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">border_hatch_weight&nbsp;=&nbsp;1.0,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">center&nbsp;=&nbsp;[Grid(id='p1021', ...), Grid(id='p1026', ...)],</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">context_menu&nbsp;=&nbsp;'auto',</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">css_classes&nbsp;=&nbsp;[],</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">css_variables&nbsp;=&nbsp;{},</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">disabled&nbsp;=&nbsp;False,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">elements&nbsp;=&nbsp;[],</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">extra_x_ranges&nbsp;=&nbsp;{},</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">extra_x_scales&nbsp;=&nbsp;{},</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">extra_y_ranges&nbsp;=&nbsp;{},</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">extra_y_scales&nbsp;=&nbsp;{},</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">flow_mode&nbsp;=&nbsp;'block',</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">frame_align&nbsp;=&nbsp;True,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">frame_height&nbsp;=&nbsp;None,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">frame_width&nbsp;=&nbsp;None,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">height&nbsp;=&nbsp;400,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">height_policy&nbsp;=&nbsp;'auto',</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">hidpi&nbsp;=&nbsp;True,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">hold_render&nbsp;=&nbsp;False,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">html_attributes&nbsp;=&nbsp;{},</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">html_id&nbsp;=&nbsp;None,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_event_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_property_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">left&nbsp;=&nbsp;[LinearAxis(id='p1022', ...)],</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_factor&nbsp;=&nbsp;10,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_interval&nbsp;=&nbsp;300,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_threshold&nbsp;=&nbsp;2000,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_timeout&nbsp;=&nbsp;500,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">margin&nbsp;=&nbsp;None,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">match_aspect&nbsp;=&nbsp;False,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">max_height&nbsp;=&nbsp;None,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">max_width&nbsp;=&nbsp;None,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border&nbsp;=&nbsp;5,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_bottom&nbsp;=&nbsp;None,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_left&nbsp;=&nbsp;None,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_right&nbsp;=&nbsp;None,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_top&nbsp;=&nbsp;None,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_height&nbsp;=&nbsp;None,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_width&nbsp;=&nbsp;None,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">name&nbsp;=&nbsp;None,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_alpha&nbsp;=&nbsp;1.0,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_cap&nbsp;=&nbsp;'butt',</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_color&nbsp;=&nbsp;'#e5e5e5',</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_dash&nbsp;=&nbsp;[],</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_dash_offset&nbsp;=&nbsp;0,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_join&nbsp;=&nbsp;'bevel',</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_width&nbsp;=&nbsp;1,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">output_backend&nbsp;=&nbsp;'canvas',</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">renderers&nbsp;=&nbsp;[GlyphRenderer(id='p1046', ...)],</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">reset_policy&nbsp;=&nbsp;'standard',</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">resizable&nbsp;=&nbsp;False,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">right&nbsp;=&nbsp;[],</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">sizing_mode&nbsp;=&nbsp;None,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">styles&nbsp;=&nbsp;{},</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">stylesheets&nbsp;=&nbsp;[],</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">subscribed_events&nbsp;=&nbsp;PropertyValueSet(),</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">syncable&nbsp;=&nbsp;True,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">tags&nbsp;=&nbsp;[],</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">title&nbsp;=&nbsp;Title(id='p1013', ...),</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">title_location&nbsp;=&nbsp;'above',</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">toolbar&nbsp;=&nbsp;Toolbar(id='p1014', ...),</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">toolbar_inner&nbsp;=&nbsp;False,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">toolbar_location&nbsp;=&nbsp;'right',</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">toolbar_sticky&nbsp;=&nbsp;True,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">visible&nbsp;=&nbsp;True,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">width&nbsp;=&nbsp;600,</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">width_policy&nbsp;=&nbsp;'auto',</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">window_axis&nbsp;=&nbsp;'none',</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">x_range&nbsp;=&nbsp;DataRange1d(id='p1007', ...),</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">x_scale&nbsp;=&nbsp;LinearScale(id='p1015', ...),</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">y_range&nbsp;=&nbsp;DataRange1d(id='p1008', ...),</div></div><div class=\"p1052\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">y_scale&nbsp;=&nbsp;LinearScale(id='p1016', ...))</div></div></div>\n",
              "<script>\n",
              "(function() {\n",
              "  let expanded = false;\n",
              "  const ellipsis = document.getElementById(\"p1053\");\n",
              "  ellipsis.addEventListener(\"click\", function() {\n",
              "    const rows = document.getElementsByClassName(\"p1052\");\n",
              "    for (let i = 0; i < rows.length; i++) {\n",
              "      const el = rows[i];\n",
              "      el.style.display = expanded ? \"none\" : \"table-row\";\n",
              "    }\n",
              "    ellipsis.innerHTML = expanded ? \"&hellip;)\" : \"&lsaquo;&lsaquo;&lsaquo;\";\n",
              "    expanded = !expanded;\n",
              "  });\n",
              "})();\n",
              "</script>\n"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "draw_vectors(word_tsne[:, 0], word_tsne[:, 1], color='green', token=words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EyGtAv70np5"
      },
      "source": [
        "### Visualizing phrases\n",
        "\n",
        "Word embeddings can also be used to represent short phrases. The simplest way is to take __an average__ of vectors for all tokens in the phrase with some weights.\n",
        "\n",
        "This trick is useful to identify what data are you working with: find if there are any outliers, clusters or other artifacts.\n",
        "\n",
        "Let's try this new hammer on our data!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mkAuR3S0np5"
      },
      "outputs": [],
      "source": [
        "def get_phrase_embedding(phrase):\n",
        "    \"\"\"\n",
        "    Convert phrase to a vector by aggregating it's word embeddings. See description above.\n",
        "    \"\"\"\n",
        "    # 1. lowercase phrase\n",
        "    # 2. tokenize phrase\n",
        "    # 3. average word vectors for all words in tokenized phrase\n",
        "    # skip words that are not in model's vocabulary\n",
        "    # if all words are missing from vocabulary, return zeros\n",
        "\n",
        "    vector = np.zeros([model.vector_size], dtype='float32')\n",
        "\n",
        "    # YOUR CODE\n",
        "\n",
        "    return vector\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t71YRMUf0np5"
      },
      "outputs": [],
      "source": [
        "vector = get_phrase_embedding(\"I'm very sure. This never happened to me before...\")\n",
        "\n",
        "assert np.allclose(vector[::10],\n",
        "                   np.array([ 0.31807372, -0.02558171,  0.0933293 , -0.1002182 , -1.0278689 ,\n",
        "                             -0.16621883,  0.05083408,  0.17989802,  1.3701859 ,  0.08655966],\n",
        "                              dtype=np.float32))\n",
        "assert np.array_equal(get_phrase_embedding(\"thisisgibberish\"), np.zeros([model.vector_size], dtype='float32')), \"corner case for all missing words should be handled as described in the function comments\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbKvh7HR0np5"
      },
      "outputs": [],
      "source": [
        "# let's only consider ~5k phrases for a first run.\n",
        "chosen_phrases = data[::len(data) // 1000]\n",
        "\n",
        "# compute vectors for chosen phrases\n",
        "phrase_vectors = []  # YOUR CODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANJrqoMQ0np5"
      },
      "outputs": [],
      "source": [
        "assert isinstance(phrase_vectors, np.ndarray) and np.isfinite(phrase_vectors).all()\n",
        "assert phrase_vectors.shape == (len(chosen_phrases), model.vector_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1PL1rsM0np5"
      },
      "outputs": [],
      "source": [
        "# map vectors into 2d space with pca, tsne or your other method of choice\n",
        "# don't forget to normalize\n",
        "\n",
        "phrase_vectors_2d = TSNE().fit_transform(phrase_vectors)\n",
        "\n",
        "phrase_vectors_2d = (phrase_vectors_2d - phrase_vectors_2d.mean(axis=0)) / phrase_vectors_2d.std(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFkmIGK00np6"
      },
      "outputs": [],
      "source": [
        "draw_vectors(phrase_vectors_2d[:, 0], phrase_vectors_2d[:, 1],\n",
        "             phrase=[phrase[:50] for phrase in chosen_phrases],\n",
        "             radius=20,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8ojqjHH0np6"
      },
      "source": [
        "**There's more below! Scroll down when you're ready.**\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "### Text Classification: Prohibited Comment Classification\n",
        "\n",
        "![img](https://github.com/yandexdataschool/nlp_course/raw/master/resources/banhammer.jpg)\n",
        "\n",
        "__In this notebook__ you will build an algorithm that classifies social media comments into normal or toxic.\n",
        "Like in many real-world cases, you only have a small (10^3) dataset of hand-labeled examples to work with. We'll tackle this problem using both classical nlp methods and embedding-based approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "YNjpZ0HE0np6"
      },
      "outputs": [],
      "source": [
        "# if you're in colab, download the data:\n",
        "!wget https://raw.githubusercontent.com/yandexdataschool/nlp_course/refs/heads/2025/week01_embeddings/comments.tsv -O ./comments.tsv -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "IA9JD5e00np6",
        "outputId": "b2c6e294-2332-496a-d425-087f29151707",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     should_ban                                       comment_text\n",
              "50            0  \"Those who're in advantageous positions are th...\n",
              "250           1          Fartsalot56 says f**k you motherclucker!!\n",
              "450           1  Are you a fool? \\n\\nI am sorry, but you seem t...\n",
              "650           1    I AM NOT A VANDAL!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
              "850           0  Citing sources\\n\\nCheck out the Wikipedia:Citi..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-868d285a-5611-413a-875f-9408a842c292\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>should_ban</th>\n",
              "      <th>comment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>0</td>\n",
              "      <td>\"Those who're in advantageous positions are th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>1</td>\n",
              "      <td>Fartsalot56 says f**k you motherclucker!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>1</td>\n",
              "      <td>Are you a fool? \\n\\nI am sorry, but you seem t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>650</th>\n",
              "      <td>1</td>\n",
              "      <td>I AM NOT A VANDAL!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>850</th>\n",
              "      <td>0</td>\n",
              "      <td>Citing sources\\n\\nCheck out the Wikipedia:Citi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-868d285a-5611-413a-875f-9408a842c292')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-868d285a-5611-413a-875f-9408a842c292 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-868d285a-5611-413a-875f-9408a842c292');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e6597bed-780a-4ace-9616-1b5808b2e307\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e6597bed-780a-4ace-9616-1b5808b2e307')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e6597bed-780a-4ace-9616-1b5808b2e307 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data[50::200]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"should_ban\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comment_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Fartsalot56 says f**k you motherclucker!!\",\n          \"Citing sources\\n\\nCheck out the Wikipedia:Citing sources page for help with this. 58.8.18.35\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "data = pd.read_csv(\"comments.tsv\", sep='\\t')\n",
        "\n",
        "texts = data['comment_text'].values\n",
        "target = data['should_ban'].values\n",
        "data[50::200]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "heboRTbs0np8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "texts_train, texts_test, y_train, y_test = train_test_split(texts, target, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVYhrqMP0np8"
      },
      "source": [
        "__Note:__ it is generally a good idea to split data into train/test before anything is done to them.\n",
        "\n",
        "It guards you against possible data leakage in the preprocessing stage. For example, should you decide to select words present in obscene tweets as features, you should only count those words over the training set. Otherwise your algoritm can cheat evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qb4-WlD0np8"
      },
      "source": [
        "### Preprocessing and tokenization\n",
        "\n",
        "Comments contain raw text with punctuation, upper/lowercase letters and even newline symbols.\n",
        "\n",
        "To simplify all further steps, we'll split text into space-separated tokens using one of nltk tokenizers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Cf3fCs5g0np8",
        "outputId": "9b1bf703-137a-439e-833d-960cd5ae1b49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before: How to be a grown-up at work: replace \"fuck you\" with \"Ok, great!\".\n",
            "after: how to be a grown-up at work : replace \" fuck you \" with \" ok , great ! \" .\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "tokenizer = TweetTokenizer()\n",
        "preprocess = lambda text: ' '.join(tokenizer.tokenize(text.lower()))\n",
        "\n",
        "text = 'How to be a grown-up at work: replace \"fuck you\" with \"Ok, great!\".'\n",
        "print(\"before:\", text,)\n",
        "print(\"after:\", preprocess(text),)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYqIrsDh0np8"
      },
      "outputs": [],
      "source": [
        "# task: preprocess each comment in train and test\n",
        "\n",
        "texts_train = []  # YOUR CODE\n",
        "texts_test = []  # YOUR CODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9g-JHNd0np8"
      },
      "outputs": [],
      "source": [
        "assert texts_train[5] ==  'who cares anymore . they attack with impunity .'\n",
        "assert texts_test[89] == 'hey todds ! quick q ? why are you so gay'\n",
        "assert len(texts_test) == len(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LVTr8z50np9"
      },
      "source": [
        "### Solving it: bag of words (1 point)\n",
        "\n",
        "![img](http://www.novuslight.com/uploads/n/BagofWords.jpg)\n",
        "\n",
        "One traditional approach to such problem is to use bag of words features:\n",
        "1. build a vocabulary of frequent words (use train data only)\n",
        "2. for each training sample, count the number of times a word occurs in it (for each word in vocabulary).\n",
        "3. consider this count a feature for some classifier\n",
        "\n",
        "__Note:__ in practice, you can compute such features using sklearn. Please don't do that in the current assignment, though.\n",
        "* `from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-_ByBZC0np9"
      },
      "outputs": [],
      "source": [
        "# task: find up to k most frequent tokens in texts_train,\n",
        "# sort them by number of occurrences (highest first)\n",
        "k = 10000\n",
        "\n",
        "# YOUR CODE\n",
        "\n",
        "bow_vocabulary = []  # YOUR CODE\n",
        "\n",
        "print('example features:', sorted(bow_vocabulary)[::100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyI6Sk1b0np9"
      },
      "outputs": [],
      "source": [
        "def text_to_bow(text):\n",
        "    \"\"\" convert text string to an array of token counts. Use bow_vocabulary. \"\"\"\n",
        "    # YOUR CODE\n",
        "\n",
        "    return np.array([], 'float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4v879Yzk0np9"
      },
      "outputs": [],
      "source": [
        "X_train_bow = np.stack(list(map(text_to_bow, texts_train)))\n",
        "X_test_bow = np.stack(list(map(text_to_bow, texts_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fk7kkfud0np9"
      },
      "outputs": [],
      "source": [
        "k_max = len(set(' '.join(texts_train).split()))\n",
        "assert X_train_bow.shape == (len(texts_train), min(k, k_max))\n",
        "assert X_test_bow.shape == (len(texts_test), min(k, k_max))\n",
        "assert np.all(X_train_bow[5:10].sum(-1) == np.array([len(s.split()) for s in  texts_train[5:10]]))\n",
        "assert len(bow_vocabulary) <= min(k, k_max)\n",
        "assert X_train_bow[6, bow_vocabulary.index('.')] == texts_train[6].split().count('.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBfgcxOs0np9"
      },
      "source": [
        "We shall use a simple linear model: __Logistic Regression__.\n",
        "It might not be the fanciest one around, but the simplicity has its own advantages: a linear model is blazingly fast and needs less data to fit.\n",
        "Let's sklearn it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-4kEc9b0np9"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "bow_model = None  # YOUR CODE HERE - train a logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_4W_EYJ0np9"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "\n",
        "for name, X, y, model in [\n",
        "    ('train', X_train_bow, y_train, bow_model),\n",
        "    ('test ', X_test_bow, y_test, bow_model)\n",
        "]:\n",
        "    proba = model.predict_proba(X)[:, 1]\n",
        "    auc = roc_auc_score(y, proba)\n",
        "    plt.plot(*roc_curve(y, proba)[:2], label='%s AUC=%.4f' % (name, auc))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], '--', color='black',)\n",
        "plt.legend(fontsize='large')\n",
        "plt.grid()\n",
        "\n",
        "test_accuracy = np.mean(bow_model.predict(X_test_bow) == y_test)\n",
        "print(f\"Model accuracy: {test_accuracy:.3f}\")\n",
        "assert test_accuracy > 0.77, \"Hint: tune the parameter C to improve performance\"\n",
        "print(\"Well done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SARVJqTI0np9"
      },
      "source": [
        "### Task: implement TF-IDF features (1 point)\n",
        "\n",
        "Not all words are equally useful. One can prioritize rare words and downscale words like \"and\"/\"or\" by using __tf-idf features__. This abbreviation stands for __text frequency/inverse document frequency__ and means exactly that:\n",
        "\n",
        "$$ \\text{feature}_i = \\frac{\\text{Count}(word_i \\in x)}{\\text{Total number of words in } x} \\times \\log\\left(\\frac{N}{\\text{Count}(word_i \\in D) + \\alpha}\\right) $$\n",
        "\n",
        "\n",
        ", where x is a single text, D is your dataset (a collection of texts), N is a total number of documents and $\\alpha$ is a smoothing hyperparameter (typically 1).\n",
        "And $Count(word_i \\in D)$ is the number of documents where $word_i$ appears.\n",
        "\n",
        "It may also be a good idea to normalize each data sample after computing tf-idf features.\n",
        "\n",
        "__Your task:__ implement tf-idf features, train a model and evaluate ROC curve. Compare it with basic BagOfWords model from above.\n",
        "\n",
        "Please don't use sklearn/nltk built-in tf-idf vectorizers in your solution :) You can still use 'em for debugging though."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkg5dIBP0np9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cW5Il530np9"
      },
      "source": [
        "Scroll down when you're done with TF-IDF!\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "### Solving it better: word vectors (1 point)\n",
        "\n",
        "Let's try another approach: instead of counting per-word frequencies, we shall map all words to pre-trained word vectors and average over them to get text features.\n",
        "\n",
        "This should give us two key advantages: (1) we now have 10^2 features instead of 10^4 and (2) our model can generalize to word that are not in training dataset.\n",
        "\n",
        "We begin with a standard approach with pre-trained word vectors. However, you may also try\n",
        "* training embeddings from scratch on relevant (unlabeled) data\n",
        "* multiplying word vectors by inverse word frequency in dataset (like tf-idf).\n",
        "* concatenating several embeddings\n",
        "    * call `gensim.downloader.info()['models'].keys()` to get a list of available models\n",
        "* clusterizing words by their word-vectors and try bag of cluster_ids\n",
        "\n",
        "__Note:__ loading pre-trained model may take a while. It's a perfect opportunity to refill your cup of tea/coffee and grab some extra cookies. Or binge-watch some tv series if you're slow on internet connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5lmIxfm0np9"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader\n",
        "embeddings = gensim.downloader.load(\"fasttext-wiki-news-subwords-300\")\n",
        "\n",
        "# If you're low on RAM or download speed, use \"glove-wiki-gigaword-100\" instead. Ignore all further asserts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njbI0PjG0np9"
      },
      "outputs": [],
      "source": [
        "def vectorize_sum(comment):\n",
        "    \"\"\"\n",
        "    implement a function that converts preprocessed comment to a sum of token vectors\n",
        "    \"\"\"\n",
        "    embedding_dim = embeddings.vectors.shape[1]\n",
        "    features = np.zeros([embedding_dim], dtype='float32')\n",
        "\n",
        "    # YOUR CODE\n",
        "\n",
        "    return features\n",
        "\n",
        "assert np.allclose(\n",
        "    vectorize_sum(\"who cares anymore . they attack with impunity .\")[::70],\n",
        "    np.array([ 0.0108616 ,  0.0261663 ,  0.13855131, -0.18510573, -0.46380025])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0TsQ7zm0np9"
      },
      "outputs": [],
      "source": [
        "X_train_wv = np.stack([vectorize_sum(text) for text in texts_train])\n",
        "X_test_wv = np.stack([vectorize_sum(text) for text in texts_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aUzBc2R0np9"
      },
      "outputs": [],
      "source": [
        "wv_model = LogisticRegression().fit(X_train_wv, y_train)\n",
        "\n",
        "for name, X, y, model in [\n",
        "    ('bow train', X_train_bow, y_train, bow_model),\n",
        "    ('bow test ', X_test_bow, y_test, bow_model),\n",
        "    ('vec train', X_train_wv, y_train, wv_model),\n",
        "    ('vec test ', X_test_wv, y_test, wv_model)\n",
        "]:\n",
        "    proba = model.predict_proba(X)[:, 1]\n",
        "    auc = roc_auc_score(y, proba)\n",
        "    plt.plot(*roc_curve(y, proba)[:2], label='%s AUC=%.4f' % (name, auc))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], '--', color='black',)\n",
        "plt.legend(fontsize='large')\n",
        "plt.grid()\n",
        "\n",
        "assert roc_auc_score(y_test, wv_model.predict_proba(X_test_wv)[:, 1]) > 0.92, \"something's wrong with your features\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qt2TpGz0np9"
      },
      "source": [
        "If everything went right, you've just managed to reduce misclassification rate by a factor of two.\n",
        "This trick is very useful when you're dealing with small datasets. However, if you have hundreds of thousands of samples, there's a whole different range of methods for that. We'll get there in the second part.\n",
        "\n",
        "**Would you like to know more?**\n",
        "* See what other embeddings are there in the model zoo: `gensim.downloader.info()`\n",
        "* Take a look at [FastText embeddings](https://github.com/facebookresearch/fastText)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}